; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -march=amdgcn -mcpu=gfx1010 -mattr=-wavefrontsize32,+wavefrontsize64 -verify-machineinstrs < %s | FileCheck -check-prefixes=GFX10 %s
; RUN: llc -march=amdgcn -mcpu=gfx1100 -mattr=-wavefrontsize32,+wavefrontsize64 -verify-machineinstrs < %s | FileCheck -check-prefixes=GFX11 %s

define dllexport amdgpu_cs void @atomic_add_in_wf(ptr addrspace(1) %arg, i32 inreg %arg1, ptr addrspace(4) inreg noundef %arg2) #0 {
; GFX10-LABEL: atomic_add_in_wf:
; GFX10:       ; %bb.0: ; %bb
; GFX10-NEXT:    s_ashr_i32 s3, s0, 31
; GFX10-NEXT:    v_add_co_u32 v0, vcc, v0, s0
; GFX10-NEXT:    v_add_co_ci_u32_e32 v1, vcc, s3, v1, vcc
; GFX10-NEXT:    s_mov_b64 s[4:5], exec
; GFX10-NEXT:    global_load_dword v0, v[0:1], off offset:4
; GFX10-NEXT:  .LBB0_1: ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_readfirstlane_b32 s0, v0
; GFX10-NEXT:    v_cmp_eq_u32_e64 s[4:5], s0, v0
; GFX10-NEXT:    s_and_saveexec_b64 s[8:9], s[4:5]
; GFX10-NEXT:    s_ashr_i32 s3, s0, 31
; GFX10-NEXT:    s_add_u32 s10, s1, s0
; GFX10-NEXT:    s_addc_u32 s11, s2, s3
; GFX10-NEXT:    v_mov_b32_e32 v0, 1
; GFX10-NEXT:    s_load_dwordx4 s[4:7], s[10:11], 0x0
; GFX10-NEXT:    v_mov_b32_e32 v1, 0
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    buffer_atomic_add v0, v1, s[4:7], 0 idxen glc
; GFX10-NEXT:    ; implicit-def: $vgpr0
; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10-NEXT:    s_xor_b64 exec, exec, s[8:9]
; GFX10-NEXT:    s_cbranch_execnz .LBB0_1
; GFX10-NEXT:  ; %bb.2:
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: atomic_add_in_wf:
; GFX11:       ; %bb.0: ; %bb
; GFX11-NEXT:    s_ashr_i32 s3, s0, 31
; GFX11-NEXT:    v_add_co_u32 v0, vcc, v0, s0
; GFX11-NEXT:    v_add_co_ci_u32_e32 v1, vcc, s3, v1, vcc
; GFX11-NEXT:    s_mov_b64 s[4:5], exec
; GFX11-NEXT:    global_load_b32 v0, v[0:1], off offset:4
; GFX11-NEXT:  .LBB0_1: ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_eq_u32_e64 s[4:5], s0, v0
; GFX11-NEXT:    s_and_saveexec_b64 s[8:9], s[4:5]
; GFX11-NEXT:    s_ashr_i32 s3, s0, 31
; GFX11-NEXT:    s_add_u32 s4, s1, s0
; GFX11-NEXT:    s_addc_u32 s5, s2, s3
; GFX11-NEXT:    v_mov_b32_e32 v0, 1
; GFX11-NEXT:    s_load_b128 s[4:7], s[4:5], 0x0
; GFX11-NEXT:    v_mov_b32_e32 v1, 0
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    buffer_atomic_add_u32 v0, v1, s[4:7], 0 idxen glc
; GFX11-NEXT:    ; implicit-def: $vgpr0
; GFX11-NEXT:    s_xor_b64 exec, exec, s[8:9]
; GFX11-NEXT:    s_cbranch_execnz .LBB0_1
; GFX11-NEXT:  ; %bb.2:
; GFX11-NEXT:    s_endpgm
bb:
  %getelementptr = getelementptr i8, ptr addrspace(1) %arg, i32 %arg1
  %load = load <2 x i32>, ptr addrspace(1) %getelementptr, align 8
  %extractelement = extractelement <2 x i32> %load, i32 0
  %extractelement3 = extractelement <2 x i32> %load, i32 1
  %call = call i32 @llvm.amdgcn.waterfall.begin.i32(i32 0, i32 %extractelement3)
  %call4 = call i32 @llvm.amdgcn.waterfall.readfirstlane.i32.i32(i32 %call, i32 %extractelement3)
  %sext = sext i32 %call4 to i64
  %getelementptr5 = getelementptr i8, ptr addrspace(4) %arg2, i64 %sext
  %load6 = load <4 x i32>, ptr addrspace(4) %getelementptr5, align 4
  %call7 = call i32 @llvm.amdgcn.struct.buffer.atomic.add.i32(i32 1, <4 x i32> %load6, i32 0, i32 0, i32 0, i32 0)
  %call8 = call i32 @llvm.amdgcn.waterfall.end.i32(i32 %call, i32 %call7)
  ret void
}

define dllexport amdgpu_cs void @atomic_add_before(ptr addrspace(1) %arg, i32 inreg %arg1, ptr addrspace(4) inreg noundef %arg2, i32 inreg %arg3) #0 {
; GFX10-LABEL: atomic_add_before:
; GFX10:       ; %bb.0: ; %bb
; GFX10-NEXT:    s_ashr_i32 s6, s0, 31
; GFX10-NEXT:    v_add_co_u32 v0, vcc, v0, s0
; GFX10-NEXT:    v_add_co_ci_u32_e32 v1, vcc, s6, v1, vcc
; GFX10-NEXT:    s_mov_b64 s[4:5], exec
; GFX10-NEXT:    global_load_dwordx2 v[0:1], v[0:1], off
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mbcnt_lo_u32_b32 v0, s4, 0
; GFX10-NEXT:    v_mbcnt_hi_u32_b32 v0, s5, v0
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX10-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX10-NEXT:    s_cbranch_execz .LBB1_2
; GFX10-NEXT:  ; %bb.1:
; GFX10-NEXT:    s_ashr_i32 s0, s3, 31
; GFX10-NEXT:    s_add_u32 s12, s1, s3
; GFX10-NEXT:    s_addc_u32 s13, s2, s0
; GFX10-NEXT:    s_bcnt1_i32_b64 s0, s[4:5]
; GFX10-NEXT:    s_load_dwordx4 s[8:11], s[12:13], 0x0
; GFX10-NEXT:    v_mov_b32_e32 v0, s0
; GFX10-NEXT:    v_mov_b32_e32 v2, 0
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    buffer_atomic_add v0, v2, s[8:11], 0 idxen
; GFX10-NEXT:  .LBB1_2:
; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX10-NEXT:    s_mov_b64 s[4:5], exec
; GFX10-NEXT:  .LBB1_3: ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10-NEXT:    v_cmp_eq_u32_e64 s[4:5], s0, v1
; GFX10-NEXT:    s_and_saveexec_b64 s[8:9], s[4:5]
; GFX10-NEXT:    s_ashr_i32 s3, s0, 31
; GFX10-NEXT:    s_add_u32 s10, s1, s0
; GFX10-NEXT:    s_addc_u32 s11, s2, s3
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v0, 1
; GFX10-NEXT:    s_load_dwordx4 s[4:7], s[10:11], 0x0
; GFX10-NEXT:    v_mov_b32_e32 v1, 0
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    buffer_atomic_add v0, v1, s[4:7], 0 idxen glc
; GFX10-NEXT:    ; implicit-def: $vgpr0_vgpr1
; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10-NEXT:    s_xor_b64 exec, exec, s[8:9]
; GFX10-NEXT:    s_cbranch_execnz .LBB1_3
; GFX10-NEXT:  ; %bb.4:
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: atomic_add_before:
; GFX11:       ; %bb.0: ; %bb
; GFX11-NEXT:    s_ashr_i32 s6, s0, 31
; GFX11-NEXT:    v_add_co_u32 v0, vcc, v0, s0
; GFX11-NEXT:    v_add_co_ci_u32_e32 v1, vcc, s6, v1, vcc
; GFX11-NEXT:    s_mov_b64 s[4:5], exec
; GFX11-NEXT:    s_mov_b64 s[6:7], exec
; GFX11-NEXT:    global_load_b64 v[0:1], v[0:1], off
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mbcnt_lo_u32_b32 v0, s4, 0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1)
; GFX11-NEXT:    v_mbcnt_hi_u32_b32 v0, s5, v0
; GFX11-NEXT:    v_cmpx_eq_u32_e32 0, v0
; GFX11-NEXT:    s_cbranch_execz .LBB1_2
; GFX11-NEXT:  ; %bb.1:
; GFX11-NEXT:    s_ashr_i32 s0, s3, 31
; GFX11-NEXT:    s_add_u32 s8, s1, s3
; GFX11-NEXT:    s_addc_u32 s9, s2, s0
; GFX11-NEXT:    s_bcnt1_i32_b64 s0, s[4:5]
; GFX11-NEXT:    s_load_b128 s[8:11], s[8:9], 0x0
; GFX11-NEXT:    v_mov_b32_e32 v0, s0
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    buffer_atomic_add_u32 v0, v2, s[8:11], 0 idxen
; GFX11-NEXT:  .LBB1_2:
; GFX11-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_mov_b64 s[4:5], exec
; GFX11-NEXT:  .LBB1_3: ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    v_readfirstlane_b32 s0, v1
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_eq_u32_e64 s[4:5], s0, v1
; GFX11-NEXT:    s_and_saveexec_b64 s[8:9], s[4:5]
; GFX11-NEXT:    s_ashr_i32 s3, s0, 31
; GFX11-NEXT:    s_add_u32 s4, s1, s0
; GFX11-NEXT:    s_addc_u32 s5, s2, s3
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v0, 1
; GFX11-NEXT:    s_load_b128 s[4:7], s[4:5], 0x0
; GFX11-NEXT:    v_mov_b32_e32 v1, 0
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    buffer_atomic_add_u32 v0, v1, s[4:7], 0 idxen glc
; GFX11-NEXT:    ; implicit-def: $vgpr0_vgpr1
; GFX11-NEXT:    s_xor_b64 exec, exec, s[8:9]
; GFX11-NEXT:    s_cbranch_execnz .LBB1_3
; GFX11-NEXT:  ; %bb.4:
; GFX11-NEXT:    s_nop 0
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
bb:
  %getelementptr = getelementptr i8, ptr addrspace(1) %arg, i32 %arg1
  %load = load <2 x i32>, ptr addrspace(1) %getelementptr, align 8
  %extractelement = extractelement <2 x i32> %load, i32 0
  %extractelement4 = extractelement <2 x i32> %load, i32 1
  %sext = sext i32 %arg3 to i64
  %getelementptr5 = getelementptr i8, ptr addrspace(4) %arg2, i64 %sext
  %load6 = load <4 x i32>, ptr addrspace(4) %getelementptr5, align 4
  %call = call i32 @llvm.amdgcn.struct.buffer.atomic.add.i32(i32 1, <4 x i32> %load6, i32 0, i32 0, i32 0, i32 0)
  %call7 = call i32 @llvm.amdgcn.waterfall.begin.i32(i32 0, i32 %extractelement4)
  %call8 = call i32 @llvm.amdgcn.waterfall.readfirstlane.i32.i32(i32 %call7, i32 %extractelement4)
  %sext9 = sext i32 %call8 to i64
  %getelementptr10 = getelementptr i8, ptr addrspace(4) %arg2, i64 %sext9
  %load11 = load <4 x i32>, ptr addrspace(4) %getelementptr10, align 4
  %call12 = call i32 @llvm.amdgcn.struct.buffer.atomic.add.i32(i32 1, <4 x i32> %load11, i32 0, i32 0, i32 0, i32 0)
  %call13 = call i32 @llvm.amdgcn.waterfall.end.i32(i32 %call7, i32 %call12)
  ret void
}

define dllexport amdgpu_cs void @atomic_add_after(ptr addrspace(1) %arg, i32 inreg %arg1, ptr addrspace(4) inreg noundef %arg2, i32 inreg %arg3) #0 {
; GFX10-LABEL: atomic_add_after:
; GFX10:       ; %bb.0: ; %bb
; GFX10-NEXT:    s_ashr_i32 s4, s0, 31
; GFX10-NEXT:    v_add_co_u32 v0, vcc, v0, s0
; GFX10-NEXT:    v_add_co_ci_u32_e32 v1, vcc, s4, v1, vcc
; GFX10-NEXT:    s_mov_b64 s[4:5], exec
; GFX10-NEXT:    global_load_dword v1, v[0:1], off offset:4
; GFX10-NEXT:  .LBB2_1: ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10-NEXT:    v_cmp_eq_u32_e64 s[6:7], s0, v1
; GFX10-NEXT:    s_and_saveexec_b64 s[6:7], s[6:7]
; GFX10-NEXT:    s_ashr_i32 s8, s0, 31
; GFX10-NEXT:    s_add_u32 s12, s1, s0
; GFX10-NEXT:    s_addc_u32 s13, s2, s8
; GFX10-NEXT:    v_mov_b32_e32 v1, 1
; GFX10-NEXT:    s_load_dwordx4 s[8:11], s[12:13], 0x0
; GFX10-NEXT:    v_mov_b32_e32 v0, 0
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    buffer_atomic_add v1, v0, s[8:11], 0 idxen glc
; GFX10-NEXT:    ; implicit-def: $vgpr1
; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10-NEXT:    s_xor_b64 exec, exec, s[6:7]
; GFX10-NEXT:    s_cbranch_execnz .LBB2_1
; GFX10-NEXT:  ; %bb.2:
; GFX10-NEXT:    s_mov_b64 exec, s[4:5]
; GFX10-NEXT:    s_mov_b64 s[4:5], exec
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mbcnt_lo_u32_b32 v1, s4, 0
; GFX10-NEXT:    v_mbcnt_hi_u32_b32 v1, s5, v1
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v1
; GFX10-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX10-NEXT:    s_cbranch_execz .LBB2_4
; GFX10-NEXT:  ; %bb.3:
; GFX10-NEXT:    s_ashr_i32 s0, s3, 31
; GFX10-NEXT:    s_add_u32 s6, s1, s3
; GFX10-NEXT:    s_addc_u32 s7, s2, s0
; GFX10-NEXT:    s_bcnt1_i32_b64 s4, s[4:5]
; GFX10-NEXT:    s_load_dwordx4 s[0:3], s[6:7], 0x0
; GFX10-NEXT:    v_mov_b32_e32 v1, s4
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    buffer_atomic_add v1, v0, s[0:3], 0 idxen
; GFX10-NEXT:  .LBB2_4:
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: atomic_add_after:
; GFX11:       ; %bb.0: ; %bb
; GFX11-NEXT:    s_ashr_i32 s4, s0, 31
; GFX11-NEXT:    v_add_co_u32 v0, vcc, v0, s0
; GFX11-NEXT:    v_add_co_ci_u32_e32 v1, vcc, s4, v1, vcc
; GFX11-NEXT:    s_mov_b64 s[4:5], exec
; GFX11-NEXT:    global_load_b32 v1, v[0:1], off offset:4
; GFX11-NEXT:  .LBB2_1: ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v1
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_eq_u32_e64 s[6:7], s0, v1
; GFX11-NEXT:    s_and_saveexec_b64 s[6:7], s[6:7]
; GFX11-NEXT:    s_ashr_i32 s9, s0, 31
; GFX11-NEXT:    s_add_u32 s8, s1, s0
; GFX11-NEXT:    s_addc_u32 s9, s2, s9
; GFX11-NEXT:    v_mov_b32_e32 v1, 1
; GFX11-NEXT:    s_load_b128 s[8:11], s[8:9], 0x0
; GFX11-NEXT:    v_mov_b32_e32 v0, 0
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    buffer_atomic_add_u32 v1, v0, s[8:11], 0 idxen glc
; GFX11-NEXT:    ; implicit-def: $vgpr1
; GFX11-NEXT:    s_xor_b64 exec, exec, s[6:7]
; GFX11-NEXT:    s_cbranch_execnz .LBB2_1
; GFX11-NEXT:  ; %bb.2:
; GFX11-NEXT:    s_mov_b64 exec, s[4:5]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1) | instskip(SKIP_3) | instid1(VALU_DEP_1)
; GFX11-NEXT:    s_mov_b64 s[4:5], exec
; GFX11-NEXT:    s_mov_b64 s[6:7], exec
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mbcnt_lo_u32_b32 v1, s4, 0
; GFX11-NEXT:    v_mbcnt_hi_u32_b32 v1, s5, v1
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cmpx_eq_u32_e32 0, v1
; GFX11-NEXT:    s_cbranch_execz .LBB2_4
; GFX11-NEXT:  ; %bb.3:
; GFX11-NEXT:    s_ashr_i32 s6, s3, 31
; GFX11-NEXT:    s_add_u32 s0, s1, s3
; GFX11-NEXT:    s_addc_u32 s1, s2, s6
; GFX11-NEXT:    s_bcnt1_i32_b64 s4, s[4:5]
; GFX11-NEXT:    s_load_b128 s[0:3], s[0:1], 0x0
; GFX11-NEXT:    v_mov_b32_e32 v1, s4
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    buffer_atomic_add_u32 v1, v0, s[0:3], 0 idxen
; GFX11-NEXT:  .LBB2_4:
; GFX11-NEXT:    s_nop 0
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
bb:
  %getelementptr = getelementptr i8, ptr addrspace(1) %arg, i32 %arg1
  %load = load <2 x i32>, ptr addrspace(1) %getelementptr, align 8
  %extractelement = extractelement <2 x i32> %load, i32 0
  %extractelement4 = extractelement <2 x i32> %load, i32 1
  %call7 = call i32 @llvm.amdgcn.waterfall.begin.i32(i32 0, i32 %extractelement4)
  %call8 = call i32 @llvm.amdgcn.waterfall.readfirstlane.i32.i32(i32 %call7, i32 %extractelement4)
  %sext9 = sext i32 %call8 to i64
  %getelementptr10 = getelementptr i8, ptr addrspace(4) %arg2, i64 %sext9
  %load11 = load <4 x i32>, ptr addrspace(4) %getelementptr10, align 4
  %call12 = call i32 @llvm.amdgcn.struct.buffer.atomic.add.i32(i32 1, <4 x i32> %load11, i32 0, i32 0, i32 0, i32 0)
  %call13 = call i32 @llvm.amdgcn.waterfall.end.i32(i32 %call7, i32 %call12)
  %sext = sext i32 %arg3 to i64
  %getelementptr5 = getelementptr i8, ptr addrspace(4) %arg2, i64 %sext
  %load6 = load <4 x i32>, ptr addrspace(4) %getelementptr5, align 4
  %call = call i32 @llvm.amdgcn.struct.buffer.atomic.add.i32(i32 1, <4 x i32> %load6, i32 0, i32 0, i32 0, i32 0)
  ret void
}

define dllexport amdgpu_cs void @atomic_add_in_wf_partial(ptr addrspace(1) %arg, i32 inreg %arg1, ptr addrspace(4) inreg noundef %arg2, i32 inreg %arg3) #0 {
; GFX10-LABEL: atomic_add_in_wf_partial:
; GFX10:       ; %bb.0: ; %bb
; GFX10-NEXT:    s_ashr_i32 s10, s0, 31
; GFX10-NEXT:    s_ashr_i32 s4, s3, 31
; GFX10-NEXT:    s_add_u32 s8, s1, s3
; GFX10-NEXT:    s_addc_u32 s9, s2, s4
; GFX10-NEXT:    v_add_co_u32 v0, vcc, v0, s0
; GFX10-NEXT:    s_load_dwordx4 s[4:7], s[8:9], 0x0
; GFX10-NEXT:    v_add_co_ci_u32_e32 v1, vcc, s10, v1, vcc
; GFX10-NEXT:    v_mov_b32_e32 v2, 1
; GFX10-NEXT:    v_mov_b32_e32 v3, 0
; GFX10-NEXT:    global_load_dwordx2 v[0:1], v[0:1], off
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    buffer_atomic_add v2, v3, s[4:7], 0 idxen
; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10-NEXT:    s_mov_b64 s[4:5], exec
; GFX10-NEXT:  .LBB3_1: ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_readfirstlane_b32 s0, v0
; GFX10-NEXT:    v_readfirstlane_b32 s3, v1
; GFX10-NEXT:    v_cmp_eq_u32_e64 s[4:5], s0, v0
; GFX10-NEXT:    v_cmp_eq_u32_e64 s[6:7], s3, v1
; GFX10-NEXT:    s_and_b64 s[4:5], s[4:5], s[6:7]
; GFX10-NEXT:    s_and_saveexec_b64 s[8:9], s[4:5]
; GFX10-NEXT:    s_ashr_i32 s3, s0, 31
; GFX10-NEXT:    s_add_u32 s10, s1, s0
; GFX10-NEXT:    s_addc_u32 s11, s2, s3
; GFX10-NEXT:    ; implicit-def: $vgpr0_vgpr1
; GFX10-NEXT:    s_load_dwordx4 s[4:7], s[10:11], 0x0
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    buffer_atomic_add v2, v3, s[4:7], 0 idxen glc
; GFX10-NEXT:    ; implicit-def: $vgpr3
; GFX10-NEXT:    ; implicit-def: $vgpr2
; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10-NEXT:    s_xor_b64 exec, exec, s[8:9]
; GFX10-NEXT:    s_cbranch_execnz .LBB3_1
; GFX10-NEXT:  ; %bb.2:
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: atomic_add_in_wf_partial:
; GFX11:       ; %bb.0: ; %bb
; GFX11-NEXT:    s_ashr_i32 s8, s0, 31
; GFX11-NEXT:    s_ashr_i32 s5, s3, 31
; GFX11-NEXT:    s_add_u32 s4, s1, s3
; GFX11-NEXT:    s_addc_u32 s5, s2, s5
; GFX11-NEXT:    v_add_co_u32 v0, vcc, v0, s0
; GFX11-NEXT:    s_load_b128 s[4:7], s[4:5], 0x0
; GFX11-NEXT:    v_add_co_ci_u32_e32 v1, vcc, s8, v1, vcc
; GFX11-NEXT:    v_mov_b32_e32 v2, 1
; GFX11-NEXT:    v_mov_b32_e32 v3, 0
; GFX11-NEXT:    global_load_b64 v[0:1], v[0:1], off
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    buffer_atomic_add_u32 v2, v3, s[4:7], 0 idxen
; GFX11-NEXT:    s_mov_b64 s[4:5], exec
; GFX11-NEXT:  .LBB3_1: ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v0
; GFX11-NEXT:    v_readfirstlane_b32 s3, v1
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_2) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX11-NEXT:    v_cmp_eq_u32_e64 s[4:5], s0, v0
; GFX11-NEXT:    v_cmp_eq_u32_e64 s[6:7], s3, v1
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_b64 s[4:5], s[4:5], s[6:7]
; GFX11-NEXT:    s_and_saveexec_b64 s[8:9], s[4:5]
; GFX11-NEXT:    s_ashr_i32 s3, s0, 31
; GFX11-NEXT:    s_add_u32 s4, s1, s0
; GFX11-NEXT:    s_addc_u32 s5, s2, s3
; GFX11-NEXT:    ; implicit-def: $vgpr0_vgpr1
; GFX11-NEXT:    s_load_b128 s[4:7], s[4:5], 0x0
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    buffer_atomic_add_u32 v2, v3, s[4:7], 0 idxen glc
; GFX11-NEXT:    ; implicit-def: $vgpr3
; GFX11-NEXT:    ; implicit-def: $vgpr2
; GFX11-NEXT:    s_xor_b64 exec, exec, s[8:9]
; GFX11-NEXT:    s_cbranch_execnz .LBB3_1
; GFX11-NEXT:  ; %bb.2:
; GFX11-NEXT:    s_nop 0
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
bb:
  %getelementptr = getelementptr i8, ptr addrspace(1) %arg, i32 %arg1
  %load = load <2 x i32>, ptr addrspace(1) %getelementptr, align 8
  %extractelement = extractelement <2 x i32> %load, i32 0
  %extractelement4 = extractelement <2 x i32> %load, i32 1
  %token = call i32 @llvm.amdgcn.waterfall.begin.i32(i32 0, i32 %extractelement)
  %sext = sext i32 %arg3 to i64
  %getelementptr5 = getelementptr i8, ptr addrspace(4) %arg2, i64 %sext
  %load6 = load <4 x i32>, ptr addrspace(4) %getelementptr5, align 4
  %call = call i32 @llvm.amdgcn.struct.buffer.atomic.add.i32(i32 1, <4 x i32> %load6, i32 0, i32 0, i32 0, i32 0)
  %token2 = call i32 @llvm.amdgcn.waterfall.begin.i32(i32 %token, i32 %extractelement4)
  %call8 = call i32 @llvm.amdgcn.waterfall.readfirstlane.i32.i32(i32 %token2, i32 %extractelement4)
  %sext9 = sext i32 %call8 to i64
  %getelementptr10 = getelementptr i8, ptr addrspace(4) %arg2, i64 %sext9
  %load11 = load <4 x i32>, ptr addrspace(4) %getelementptr10, align 4
  %call12 = call i32 @llvm.amdgcn.struct.buffer.atomic.add.i32(i32 1, <4 x i32> %load11, i32 0, i32 0, i32 0, i32 0)
  %call13 = call i32 @llvm.amdgcn.waterfall.end.i32(i32 %token2, i32 %call12)
  ret void
}



; Function Attrs: nocallback nofree nounwind willreturn
declare i32 @llvm.amdgcn.struct.buffer.atomic.add.i32(i32, <4 x i32>, i32, i32, i32, i32 immarg) #3
; Function Attrs: convergent nounwind
declare i32 @llvm.amdgcn.waterfall.begin.i32(i32, i32) #4
; Function Attrs: convergent nounwind
declare i32 @llvm.amdgcn.waterfall.readfirstlane.i32.i32(i32, i32) #4
; Function Attrs: convergent nounwind
declare i32 @llvm.amdgcn.waterfall.end.i32(i32, i32) #4

attributes #0 = { nounwind readnone convergent }
